{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we load the data directly from a csv file we do not get the data types of any columns. If we first load it into a dataframe, we get the data types of the different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:root@localhost:5432/adsdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 67: expected 16 fields, saw 17\\nSkipping line 126: expected 16 fields, saw 17\\nSkipping line 127: expected 16 fields, saw 17\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../landing_zone/persistent/countries_20211224.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(0).to_sql('countries', engine, if_exists='replace',index=False) # Drops old table and creates new empty table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global Code</th>\n",
       "      <th>Global Name</th>\n",
       "      <th>Region Code</th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Sub-region Code</th>\n",
       "      <th>Sub-region Name</th>\n",
       "      <th>Intermediate Region Code</th>\n",
       "      <th>Intermediate Region Name</th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>M49 Code</th>\n",
       "      <th>ISO-alpha2 Code</th>\n",
       "      <th>ISO-alpha3 Code</th>\n",
       "      <th>Least Developed Countries (LDC)</th>\n",
       "      <th>Land Locked Developing Countries (LLDC)</th>\n",
       "      <th>Small Island Developing States (SIDS)</th>\n",
       "      <th>Developed / Developing Countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Global Code, Global Name, Region Code, Region Name, Sub-region Code, Sub-region Name, Intermediate Region Code, Intermediate Region Name, Country or Area, M49 Code, ISO-alpha2 Code, ISO-alpha3 Code, Least Developed Countries (LDC), Land Locked Developing Countries (LLDC), Small Island Developing States (SIDS), Developed / Developing Countries]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the file can be directly imported from a csv file (which is dumb IMHO) -> Add feature to create table schema beforehand\n",
    "import csv\n",
    "with open('../landing_zone/persistent/countries_20211224.csv', newline='', encoding='utf-8-sig') as f:\n",
    "  reader = csv.reader(f)\n",
    "  row1 = next(reader)\n",
    "\n",
    "cols = pd.DataFrame(columns = row1)\n",
    "cols.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidTextRepresentation",
     "evalue": "invalid input syntax for type bigint: \"SAF15902\"\nCONTEXT:  COPY acled_20211224, line 1, column iso: \"SAF15902\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidTextRepresentation\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9268/4045847124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acled_20211224'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# null values become ''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidTextRepresentation\u001b[0m: invalid input syntax for type bigint: \"SAF15902\"\nCONTEXT:  COPY acled_20211224, line 1, column iso: \"SAF15902\"\n"
     ]
    }
   ],
   "source": [
    "# If we want to insert from a dataframe\n",
    "conn = engine.raw_connection() # Starts the connection using the provided engine - Difference between raw and standard?\n",
    "cur = conn.cursor()\n",
    "output = io.StringIO()\n",
    "df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "output.seek(0)\n",
    "contents = output.getvalue()\n",
    "cur.copy_from(output, 'acled_20211224', null=\"\") # null values become ''\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../landing_zone/persistent/acled_20211224.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def psql_insert_copy(table, conn, keys, data_iter):\n",
    "    import csv\n",
    "    from io import StringIO\n",
    "    from sqlalchemy import create_engine\n",
    "    \n",
    "    # gets a DBAPI connection that can provide a cursor\n",
    "    dbapi_conn = conn.connection\n",
    "    with dbapi_conn.cursor() as cur:\n",
    "        s_buf = StringIO()\n",
    "        writer = csv.writer(s_buf)\n",
    "        writer.writerows(data_iter)\n",
    "        s_buf.seek(0)\n",
    "\n",
    "        columns = ', '.join('\"{}\"'.format(k) for k in keys)\n",
    "        if table.schema:\n",
    "            table_name = '{}.{}'.format(table.schema, table.name)\n",
    "        else:\n",
    "            table_name = table.name\n",
    "\n",
    "        sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(\n",
    "            table_name, columns)\n",
    "        cur.copy_expert(sql=sql, file=s_buf)\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:root@localhost:5432/adsdb')\n",
    "df.to_sql('acled_20211224', engine, method=psql_insert_copy, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below there is an idea on how to convert csv into sql directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_load(filename, db_url):\n",
    "    \"\"\"\n",
    "    Loads the contents of the given csv into a new table in the specified database. If there is an existing table with the same name, it gets replaced. \n",
    "    It does not check for constraints whatsoever.\n",
    "\n",
    "    Input:\n",
    "        .csv file and database url.\n",
    "    \n",
    "    Output:\n",
    "        Table in the specified database.\n",
    "    \n",
    "    * Could be done such that the pwd is specified in a different attribute, etc.\n",
    "    \"\"\"\n",
    "    import psycopg2\n",
    "    from sqlalchemy import create_engine\n",
    "    import io\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    import os\n",
    "\n",
    "    # Initialize engine\n",
    "    engine = create_engine(db_url)\n",
    "    \n",
    "    # Create table from the specified file\n",
    "    with open(filename, newline='', encoding='utf-8-sig') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "\n",
    "    table_name = os.path.basename(filename)[:-4]\n",
    "    cols = pd.DataFrame(columns = header)\n",
    "    cols.head(0).to_sql(table_name, engine, if_exists='replace',index=False) # Drops old table and creates new empty table\n",
    "\n",
    "    data = open(filename, 'r', encoding='utf-8-sig')\n",
    "\n",
    "    # Insert the contents \n",
    "    conn = engine.raw_connection() # Starts the connection using the provided engine - Difference between raw and standard?\n",
    "    cur = conn.cursor() # Initializes the cursor\n",
    "    query = 'COPY {} FROM STDIN WITH CSV HEADER'.format(table_name)\n",
    "    cur.copy_expert(query, data)\n",
    "    # cur.copy_from(output, table_name, null=\"\") # null values become ''\n",
    "    conn.commit() # Commits the inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../landing_zone/persistent/acled_20211224.csv'\n",
    "database_url = 'postgresql+psycopg2://postgres:root@localhost:5432/adsdb'\n",
    "bulk_load(filename, database_url)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b65f8c67370667d0adc9e610192d3d771ab29a08e3746b752a6b11121b80b184"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
