def years_dimension(colname='id'):
    import datetime
    import numpy as np
    import pandas as pd
    
    starting_year = 1900
    current_year = int(datetime.datetime.now().date().strftime('%Y'))
    year_list = np.arange(starting_year, current_year+1)
    df = pd.DataFrame(year_list, columns=[colname])
    return df

def create_schema(db_url, schema_path):
    """
    Create schema in the scpecified db.
    """
    import sqlalchemy
    from sqlalchemy import create_engine

    schema = open(schema_path)
    engine = create_engine(db_url)

    escaped_sql = sqlalchemy.text(schema.read())
    engine.execute(escaped_sql)

    return

def populate_schema(db_url_source, db_url_schema):
    """
    Populate schema with the proper data.
    """
    import numpy as np
    import pandas as pd
    import sqlalchemy
    from sqlalchemy import create_engine
    from sqlalchemy import inspect
    from sqlalchemy import MetaData
    from sqlalchemy.dialects.postgresql import insert as pg_insert

    engine_schema = create_engine(db_url_schema)
    schema_conn = engine_schema.connect()
    inspector = inspect(engine_schema)
    schema_table_names = inspector.get_table_names()

    engine_source = create_engine(db_url_source)
    source_conn = engine_source.connect()

    facts = []
    for table in schema_table_names:
        if 'dim' not in table:
            facts.append(table)
            continue

        else: 
            if table == 'years_dim':
                data = years_dimension().to_dict('records')
            
            else:
                df_schema = pd.read_sql_table(table, schema_conn)
                df_source = pd.read_sql_table(table, source_conn)

                cols = np.intersect1d(df_schema.columns, df_source.columns)
                data = df_source[cols].to_dict('records')

            meta = MetaData()
            meta.reflect(bind=engine_schema)   
            stmt = pg_insert(meta.tables[table]).values(data).on_conflict_do_nothing()
            schema_conn.execute(stmt)

    for table in facts:
        df_schema = pd.read_sql_table(table, schema_conn)
        df_source = pd.read_sql_table(table, source_conn)

        cols = np.intersect1d(df_schema.columns, df_source.columns)
        data = df_source[cols].to_dict('records')

        meta = MetaData()
        meta.reflect(bind=engine_schema)   
        stmt = pg_insert(meta.tables[table]).values(data).on_conflict_do_nothing()
        schema_conn.execute(stmt)

    source_conn.close()
    schema_conn.close()
    return